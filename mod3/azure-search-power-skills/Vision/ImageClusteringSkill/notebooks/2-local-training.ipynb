{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the parameters for the local training, if running on your own data, experiment with the ```eps``` metric.\n",
    "For more info on the parameters go to https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweak the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters - change these for a \n",
    "input_dir = \"../data/train\"\n",
    "fraction = 1.0 ## Randomly select fraction of images for training\n",
    "model_name = \"books\" ## The name of the model we will save\n",
    "metric = \"cosine\"  ## The metric we use to determine similarity for more info see https://docs.scipy.org/doc/scipy/reference/spatial.distance.html\n",
    "min_samples = 3\n",
    "eps = 0.64  ## The maximum distance between two samples for one to be considered as in the neighborhood of the other. This is not a maximum bound on the distances of points within a cluster. This is the most important DBSCAN parameter to choose appropriately for your data set and distance function.\n",
    "report_n_samples = 3\n",
    "recursive = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and see the clusters found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will train a model on the data and show the clusters. All data with a cluster with value -1 could not be\n",
    "clustered, all other numbers represent the cluster id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import logging\n",
    "import tempfile\n",
    "import os\n",
    "import argparse\n",
    "from os.path import join\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "from ml.utils.image import read_images_from_list, show_images\n",
    "import logging \n",
    "import matplotlib.pyplot as plt\n",
    "import ipyplot\n",
    "\n",
    "from ml.extractors.vgg16_extractor import VGG16Extractor\n",
    "from ml.models.DBSCAN import DBSCANv2\n",
    "from ml.similarity.detector import ImageSimilarityDetector\n",
    "from ml.utils.image import read_images_from_folder\n",
    "\n",
    "# Setup extractor, model and similarity detector \n",
    "print(\"Creating image similarity model...\")\n",
    "extractor = VGG16Extractor()\n",
    "model = DBSCANv2(eps=eps, min_samples=min_samples, metric=metric)\n",
    "detector = ImageSimilarityDetector(extractor, model)\n",
    "\n",
    "\n",
    "# List the input folder\n",
    "print(\"Reading images from %s...\", input_dir)\n",
    "files = []\n",
    "\n",
    "for r, _, f in os.walk(input_dir):\n",
    "    for file in f:\n",
    "        files.append(join(r, file))\n",
    "    if not recursive:\n",
    "        break\n",
    "# Randomly select fraction of images for training\n",
    "files = random.sample(files, int(len(files) * fraction))\n",
    "# Read images\n",
    "images, _ = read_images_from_list(files)\n",
    "\n",
    "# Training model\n",
    "print(\"Training similarity model...\")\n",
    "labels = detector.train(images)\n",
    "\n",
    "# Saving model\n",
    "path = '../custom-skills-deployment/models/'\n",
    "report_path = '../models'\n",
    "print(\"Training completed. Registering model...\")\n",
    "file_name = f'{model_name}.pkl'\n",
    "tags = {\n",
    "    \"min_samples\": min_samples,\n",
    "    \"eps\": eps,\n",
    "    \"metric\": metric\n",
    "}\n",
    "joblib.dump(value=detector.model, filename=os.path.join(path, file_name))\n",
    "\n",
    "# Saving clustering report\n",
    "if not os.path.isdir(path):\n",
    "    os.makedirs(os.path.join(report_path, 'report'))\n",
    "else:\n",
    "    cluster_ids = np.unique(labels)\n",
    "    for cluster_id in cluster_ids:\n",
    "        sub_images = images[labels == cluster_id]\n",
    "        cluster = np.random.choice(sub_images, min(report_n_samples, len(sub_images)), replace=False)\n",
    "        cluster_labels = [cluster_id] * len(cluster)\n",
    "        fig = show_images(cluster, cols=4, titles=cluster_labels)\n",
    "        fig.savefig(os.path.join(report_path, 'report', f'cluster_{cluster_id}_samples.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33f291de0fd92b8a6f9f38894d1e3345d92874d6adb2586114aeb76b419608b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ipykernel_py3': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}